{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIa-poEHfw5Z"
      },
      "source": [
        "#Assignment 1 (Random Forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGU057DfgTIL"
      },
      "source": [
        "* In this project you are given a dataset of housing housing price prediction. \n",
        "Dataset description is found in the given datasets.\n",
        "\n",
        "* The goal of the project is to predict the price of a house given its attributes. \n",
        "Therefore, the problem is a regression task. \n",
        "\n",
        "* You need to build a random forest that consists of multiple decision trees (for regression) from the given training data set. Then, apply it on the test set and submit your code to generate predictions.\n",
        "You need to build the random forest and decision trees from scratch. (I.e., it is not allowed to use existing machine learning libraries or packages such as sklearn.)\n",
        "\n",
        "* You may use any programming language/environment of your choice, but you are required to submit the complete source code to produce the output\n",
        "If you use anything other than jupyter notebook, submit an executable and run that from the main function of the jupyter notebook so that the prediction generation is automated. We can provide assistance with this.\n",
        "The output (a single file with the predictions for each test instance) must be generated automatically using the approach implemented by you. Submitting predictions/code from any other source (Internet, another student, etc.) is considered cheating and will result in immediate disqualification (i.e., dismissal from the course)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kut1m20f4zR"
      },
      "source": [
        "##Part 1: Preprocessing and dataset analysis (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yANfSgagRJq"
      },
      "source": [
        "* The given dataset is quite complex, it has many attributes, and not all of them are useful! \n",
        "Training on such dataset results in a bad accuracy. And this is exactly the point! \n",
        "\n",
        "* \"Understanding the question is half the answer\". In data mining, understanding the dataset is half the answer! \n",
        "\n",
        "* In part 1 you need to analyze the dataset and make it clean. \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4xjsBzYlfjq"
      },
      "source": [
        "###Load the dataset and explore (5 points)\n",
        "\n",
        "* Load the dataset, view the dataset and the shape of it, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AUvifadOf4G-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Viewing the training dataset -----\n",
            "Shape: (1460, 81) (rows, columns)\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "----- Viewing the test dataset -----\n",
            "Shape: (1560, 80) (rows, columns)\n",
            "\n",
            "First 5 rows:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
            "\n",
            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0       0      6    2010        WD         Normal  \n",
            "1   12500      6    2010        WD         Normal  \n",
            "2       0      3    2010        WD         Normal  \n",
            "3       0      6    2010        WD         Normal  \n",
            "4       0      1    2010        WD         Normal  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "\n",
            "=== Missing Values in Training Data ===\n",
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      259\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_df = pd.read_csv('housing_price_train.csv')\n",
        "test_df = pd.read_csv('housing_price_test.csv')\n",
        "\n",
        "# Display basic information about the datasets\n",
        "print(\"----- Viewing the training dataset -----\")\n",
        "print(train_df.head())\n",
        "#Header already shows the shape\n",
        "#print(f\"Shape: {test_df.shape} (rows, columns)\")\n",
        "\n",
        "\n",
        "print(\"\\n----- Viewing the test dataset -----\")\n",
        "print(test_df.head())\n",
        "\n",
        "\n",
        "# Check for missing values (example for training data)\n",
        "print(\"\\n=== Missing Values in Training Data ===\")\n",
        "print(train_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWmPCu5hmAIj"
      },
      "source": [
        "### Clean the dataset (10 points)\n",
        "\n",
        "* We cannot train on a 'dirty' dataset! There are duplicated, Null, and missing values that you need to take care of!\n",
        "\n",
        "* Drop all columns which have null values >= 70 % and drop all rows which have null values >= 70 %.\n",
        "\n",
        "* You need to take care of categorial data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "exQbzeH7mM-I"
      },
      "outputs": [],
      "source": [
        "def PreprocessingData(db):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset:\n",
        "    - Show NULL values for each column and their percentage.\n",
        "    - Drop all columns with null values >= 70%.\n",
        "    - Drop all rows with null values >= 70%.\n",
        "    - Fill missing values with the mean (numerical) or mode (categorical).\n",
        "    \"\"\"\n",
        "    # Parse headers and data\n",
        "    headers = db[0].strip().split(',')\n",
        "    data = [row.strip().split(',') for row in db[1:]]\n",
        "    \n",
        "    rows_len = len(data)\n",
        "    cols_len = len(headers)\n",
        "\n",
        "    # Step 1: Drop rows with null values >= 70%\n",
        "    # Goes through each row, to check the corresponding data \n",
        "    # Count and check if the total empty row exceeds 70%\n",
        "    valid_rows = []\n",
        "    for row in data:\n",
        "        null_count = sum(1 for value in row if value.strip() == '')\n",
        "        if null_count / cols_len < 0.7:\n",
        "            valid_rows.append(row)\n",
        "    data = valid_rows\n",
        "    \n",
        "    # Step 2: Drop columns with null values >= 70%\n",
        "    # Goes through each row, to check the corresponding data for the columns\n",
        "    cols_to_keep = []\n",
        "    for col_idx in range(cols_len):\n",
        "        null_count = sum(1 for row in data if row[col_idx].strip() == '')\n",
        "        if null_count / rows_len < 0.7:\n",
        "            cols_to_keep.append(col_idx)\n",
        "     # When a col gets deleted, so does the header. Keep a list of deleted indexes for the column\n",
        "    headers = [headers[i] for i in cols_to_keep]\n",
        "    data = [[row[i] for i in cols_to_keep] for row in data]\n",
        "    \n",
        "    # Step 3: Fill missing values\n",
        "    for col_idx, _ in enumerate(headers):\n",
        "        # create a list of the corresponding data type\n",
        "        col_values = [row[col_idx] for row in data]\n",
        "        # Create a list of indices, where there are empty\n",
        "        null_indices = [i for i, val in enumerate(col_values) if val.strip() == '']\n",
        "        \n",
        "        # First try numerical, if error, try categorical\n",
        "        try:\n",
        "            float_values = [float(val) for val in col_values if val.strip() != '']\n",
        "            mean_value = sum(float_values) / len(float_values)\n",
        "            for idx in null_indices:\n",
        "                data[idx][col_idx] = str(mean_value)\n",
        "        except ValueError:\n",
        "            mode_value = max(set(col_values), key=col_values.count)\n",
        "            for idx in null_indices:\n",
        "                data[idx][col_idx] = mode_value\n",
        "    \n",
        "    # Recombine headers and data\n",
        "    cleaned_db = [','.join(headers)] + [','.join(row) for row in data]\n",
        "    return cleaned_db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ8kz_a-mdNx"
      },
      "source": [
        "\n",
        "### Correlations! (5 points)\n",
        "\n",
        "* Now we have a clean dataset, but not all attributes are useful! \n",
        "\n",
        "* Display the corrlation between all features and the sales price. This will show you which feature affects sales price more. You may use *corr()* function. \n",
        "\n",
        "* Choose the most correlated features, and remove others. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Irh60fo-nVtw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Id  SalePrice\n",
            "Id         1.000000  -0.079092\n",
            "SalePrice -0.079092   1.000000\n",
            "--------------------------------\n",
            "Id          -0.079092\n",
            "SalePrice    1.000000\n",
            "Name: SalePrice, dtype: float64\n",
            "Id           False\n",
            "SalePrice     True\n",
            "Name: SalePrice, dtype: bool\n",
            "--------------------------------\n",
            "   SalePrice\n",
            "0     115000\n",
            "1     158000\n",
            "2     173000\n",
            "3     178000\n",
            "4     220000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(correlation_matrix)\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "print(correlation_matrix['SalePrice'])\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "correlated_features= correlation_matrix['SalePrice'].abs() > 0.5\n",
        "selected_features = df.columns[correlated_features]\n",
        "df_filtered = df[selected_features]\n",
        "\n",
        "print(df_filtered.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnNAO-wnXM6"
      },
      "source": [
        "## Part 2: Decision Tree (45 points)\n",
        "#### Building a Decision Tree:\n",
        "A Decision tree consists of nodes connected by edges. A decision tree is typically, a binary tree, which has the following properties:\n",
        "- One node is marked as Root node\n",
        "- Every node other than the root has a parent node\n",
        "- Each node can have at most 2 child nodes (left edge & right edge)\n",
        "- Leaf node is the node which contains pure data or when we reach to the maximum depth \n",
        "\n",
        "To create the decision tree model for scratch you need to create two classes (a class for the node, for example \"class DecisionNode():\" and a class for Decision Tree model, for example \"class RegressionDecisionTree():\")\n",
        "\n",
        "\n",
        "1- DecisionNode class used to save some values for each node we do the spliting on it until we reach the leaf node\n",
        "so we will save the following values for the node:\n",
        "- feature: feature index.\n",
        "- threshold: the value we used to split the data on.\n",
        "- value: the average value for the leaf node.\n",
        "- True_Branch: if the condition is true.\n",
        "- False_Branch: if the condition is false."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Correlations! (5 points)\n",
        "\n",
        "* Now we have a clean dataset, but not all attributes are useful! \n",
        "\n",
        "* Display the corrlation between all features and the sales price. This will show you which feature affects sales price more. You may use *corr()* function. \n",
        "\n",
        "* Choose the most correlated features, and remove others. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cYNFB7QY-SJK"
      },
      "outputs": [],
      "source": [
        "class DecisionNode():\n",
        "    def __init__(self, feature_idx=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
        "        self.feature_idx = feature_idx # index of the feature that is used\n",
        "        self.threshold = threshold     # threshold value for feature when making the decision\n",
        "        self.value = value # Average value if the node is a leaf in the tree\n",
        "        self.true_branch = true_branch # the node we go to if decision returns True\n",
        "        self.false_branch = false_branch # the node we go to if decision returns False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpCv95F-SJK"
      },
      "source": [
        "# Decision Tree Class\n",
        "This Class consists the following functions:\n",
        "<ol>\n",
        "<li> <b>build_tree</b>: used to create the decision tree nodes</li> \n",
        "<li> <b>calc_variance_reduction</b> : measure the impurity by using variance reduction measure (like MSE) </li> \n",
        "the function takes three parameters (parentRec: the records for the target before split,and the left and right records after splitting. This function used to measure the impurity for each node and decide if we will split or not.\n",
        "<li> <b>majority_vote</b>: used to calculate values for the leaf nodes records which equal to the mean of these records.</li> \n",
        "<li><b>split_by_feature</b>: this function take the feature and the threshold and check if the feature is numerical so it split the records into two node (true which is the left edge and false which is the right edge)\n",
        "if the feature is categorical so it split where the values equal to the threshold</li>\n",
        "<li> <b>fit</b>: Used to train the dataset after spliting the data into two part x: features, y: target</li>\n",
        "<li><b>predict_value</b>: used to predict the value for each record, it is a recursive method to find the leaf node that corresponds to prediction\n",
        "<li><b>predict</b>: take all records for the test data and iterate into each record to predit the y(target) value and save the result into a prediction list. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HSe6v4r1-SJK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class RegressionDecisionTree():\n",
        "    # constructor\n",
        "    def __init__(self, min_VarianceReduction=1e-7, max_depth=5):        \n",
        "        self.root = None # root of this tree\n",
        "        self.min_VarianceReduction = min_VarianceReduction # minimum VarianceReduction to allow splitting\n",
        "        # used to stopping conductions\n",
        "        self.max_depth = max_depth # maximum depth the tree grows to\n",
        " \n",
        "\n",
        "    # used to create the decision tree nodes\n",
        "    def build_tree(self, X, y, current_depth=0):\n",
        "        # we will use decision dictionary to save the feature and the threshold we build the tree on \n",
        "        decision = None\n",
        "        # we will use subtrees dictionary to save the feature and the threshold we build the tree on \n",
        "        subtrees = None\n",
        "        largest_variance_Reduction = 0\n",
        "        # add y as last column of X\n",
        "        df = pd.concat((X, y), axis=1)\n",
        "        n_rows, n_features = X.shape\n",
        "        if current_depth <= self.max_depth:\n",
        "            # iterate through every feature\n",
        "            for feature_idx in range(n_features):\n",
        "                # values of that column\n",
        "                feature_values = X.iloc[:, feature_idx]                \n",
        "                unique_values = feature_values.unique()                \n",
        "                for threshold in unique_values:\n",
        "                    X_trueEdge, X_falseEdge = self.split_by_feature(df, feature_idx, threshold)\n",
        "                    if len(X_trueEdge) > 0 and len(X_falseEdge) > 0:\n",
        "                        y_true = X_trueEdge.iloc[:,-1]\n",
        "                        y_false = X_falseEdge.iloc[:,-1]                        \n",
        "                        # Calculate impurity\n",
        "                        VarianceRed = self.Calc_variance_reduction(y, y_true, y_false)\n",
        "                        # Keep track of which feature gave the largest information gain\n",
        "                        if VarianceRed > largest_variance_Reduction:\n",
        "                            largest_variance_Reduction = VarianceRed\n",
        "                            decision = {\"feature_idx\":feature_idx, \"threshold\":threshold}\n",
        "                            subtrees = {\"X_true\":X_trueEdge.iloc[:,:-1],\n",
        "                                        \"y_true\":y_true,\n",
        "                                        \"X_false\":X_falseEdge.iloc[:,:-1],\n",
        "                                        \"y_false\":y_false}\n",
        "\n",
        "        # we will construct new branch of tree if the variance_Reduction is larger than minimum variance_Reduction that we've defined\n",
        "        if largest_variance_Reduction > self.min_VarianceReduction:\n",
        "            true_branch = self.build_tree(subtrees[\"X_true\"], subtrees[\"y_true\"], current_depth+1)\n",
        "            false_branch = self.build_tree(subtrees[\"X_false\"], subtrees[\"y_false\"], current_depth+1)\n",
        "            return DecisionNode(feature_idx=decision[\"feature_idx\"], threshold=decision[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
        "\n",
        "        # at leaf node we calculate the mean for the records\n",
        "        leaf_value = self.majority_vote(y)\n",
        "        return DecisionNode(value=leaf_value)\n",
        "                        \n",
        "    # measure the impurity by using variance reduction measure (like MSE)\n",
        "    # left_edgeRec= True edge: where condition is true\n",
        "    # Right_edgeRec= False edge: where condition is false\n",
        "    def Calc_variance_reduction(self, parentRec, left_edgeRec, Right_edgeRec):   \n",
        "        # return the VarReduction = variance for parent - (Weight * var(leftEdge) + Weight * var(RightEdge)\n",
        "        var_parent = np.var(parentRec)\n",
        "        \n",
        "        weight_left = len(left_edgeRec) / len(parentRec)\n",
        "        weight_right = len(Right_edgeRec) / len(parentRec)\n",
        "        var_left = np.var(left_edgeRec)\n",
        "        var_right = np.var(Right_edgeRec)\n",
        "\n",
        "        VarReduction = var_parent - (weight_left * var_left + weight_right * var_right)\n",
        "        return VarReduction\n",
        "        \n",
        "    \n",
        "    def majority_vote(self, Y): \n",
        "        # return the majority_vote for the leaf nodes \n",
        "        return Y.mean()\n",
        "        \n",
        "             \n",
        "    def split_by_feature(self, db, feature_idx, threshold):\n",
        "        # split the data into left_edge & right_edge depends one specified feature and the threshold\n",
        "        left_edge = db[db.iloc [:, feature_idx] <= threshold]\n",
        "        right_edge = db[db.iloc [:, feature_idx] > threshold]\n",
        "        # return left & right edges\n",
        "        return left_edge, right_edge\n",
        "\n",
        "    \n",
        "    # Used to train the dataset after spliting the data into x: features, y: target\n",
        "    def fit(self, X, y):\n",
        "        self.root = self.build_tree(X, y)\n",
        "\n",
        "\n",
        "    def predict_value(self, xTest, tree=None):\n",
        "        # recursive method to find the leaf node that corresponds to prediction\n",
        "        if tree is None:\n",
        "            tree = self.root\n",
        "        \n",
        "        # If it's a leaf node, return the value\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "        \n",
        "        if xTest[tree.feature_idx] <= tree.threshold:\n",
        "            return self.predict_value(xTest, tree.true_branch)\n",
        "        else:\n",
        "            return self.predict_value(xTest, tree.false_branch) \n",
        "\n",
        "    # to predict the value we need to pass the all records for features and we save the prediction for each records into a list\n",
        "    def predict(self, XTest):\n",
        "        y_pred = []\n",
        "        for idx, row in XTest.iterrows():           \n",
        "            y_pred.append(self.predict_value(row.values))\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9aqjovq-SJM"
      },
      "source": [
        "- To Check the Accuracy for our prediction we use CalcAccuracy function which take the actual values for the test dataset and the predicted values and apply the RMSE formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "24p2WfE8-SJN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def CalcAccuracy(Actual_Y, Predicted_y):\n",
        "    Actual_Y = np.array(Actual_Y)\n",
        "    Predicted_y = np.array(Predicted_y)\n",
        "    \n",
        "    # Calculate the squared differences\n",
        "    squared_diff = (Actual_Y - Predicted_y) ** 2\n",
        "    \n",
        "    # Calculate the mean of the squared differences\n",
        "    mean_squared_diff = np.mean(squared_diff)\n",
        "    \n",
        "    # Take the square root to get RMSE\n",
        "    rmse = np.sqrt(mean_squared_diff)\n",
        "    \n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_2Ve9v--SJN"
      },
      "source": [
        "- Build decision tree model\n",
        "- Fit the model\n",
        "- Predict the values from test data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7dJKxolT-SJN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:178: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[feature].fillna(na_value, inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:178: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[feature].fillna(na_value, inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_12420\\3236886989.py:187: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        },
        {
          "ename": "UFuncTypeError",
          "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U21'), dtype('<U24')) -> None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 231\u001b[0m\n\u001b[0;32m    225\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m: test_ids,\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    228\u001b[0m })\n\u001b[0;32m    229\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimized_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 231\u001b[0m optimized_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mCalcAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_submission.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimized_submission.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Submission RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimized_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[14], line 123\u001b[0m, in \u001b[0;36mCalcAccuracy\u001b[1;34m(Actual_Y, Predicted_y)\u001b[0m\n\u001b[0;32m    120\u001b[0m Predicted_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Predicted_y)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Calculate the squared differences\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m squared_diff \u001b[38;5;241m=\u001b[39m (\u001b[43mActual_Y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPredicted_y\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Calculate the mean of the squared differences\u001b[39;00m\n\u001b[0;32m    126\u001b[0m mean_squared_diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(squared_diff)\n",
            "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U21'), dtype('<U24')) -> None"
          ]
        }
      ],
      "source": [
        "class DecisionNode():\n",
        "    def __init__(self, feature_idx=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
        "        self.feature_idx = feature_idx # index of the feature that is used\n",
        "        self.threshold = threshold     # threshold value for feature when making the decision\n",
        "        self.value = value # Average value if the node is a leaf in the tree\n",
        "        self.true_branch = true_branch # the node we go to if decision returns True\n",
        "        self.false_branch = false_branch # the node we go to if decision returns False\n",
        "        \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class RegressionDecisionTree():\n",
        "    # constructor\n",
        "    def __init__(self, min_VarianceReduction=1e-7, max_depth=5):        \n",
        "        self.root = None # root of this tree\n",
        "        self.min_VarianceReduction = min_VarianceReduction # minimum VarianceReduction to allow splitting\n",
        "        # used to stopping conductions\n",
        "        self.max_depth = max_depth # maximum depth the tree grows to\n",
        " \n",
        "\n",
        "    # used to create the decision tree nodes\n",
        "    def build_tree(self, X, y, current_depth=0):\n",
        "        # we will use decision dictionary to save the feature and the threshold we build the tree on \n",
        "        decision = None\n",
        "        # we will use subtrees dictionary to save the feature and the threshold we build the tree on \n",
        "        subtrees = None\n",
        "        largest_variance_Reduction = 0\n",
        "        # add y as last column of X\n",
        "        df = pd.concat((X, y), axis=1)\n",
        "        n_rows, n_features = X.shape\n",
        "        if current_depth <= self.max_depth:\n",
        "            # iterate through every feature\n",
        "            for feature_idx in range(n_features):\n",
        "                # values of that column\n",
        "                feature_values = X.iloc[:, feature_idx]                \n",
        "                unique_values = feature_values.unique()                \n",
        "                for threshold in unique_values:\n",
        "                    X_trueEdge, X_falseEdge = self.split_by_feature(df, feature_idx, threshold)\n",
        "                    if len(X_trueEdge) > 0 and len(X_falseEdge) > 0:\n",
        "                        y_true = X_trueEdge.iloc[:,-1]\n",
        "                        y_false = X_falseEdge.iloc[:,-1]                        \n",
        "                        # Calculate impurity\n",
        "                        VarianceRed = self.Calc_variance_reduction(y, y_true, y_false)\n",
        "                        # Keep track of which feature gave the largest information gain\n",
        "                        if VarianceRed > largest_variance_Reduction:\n",
        "                            largest_variance_Reduction = VarianceRed\n",
        "                            decision = {\"feature_idx\":feature_idx, \"threshold\":threshold}\n",
        "                            subtrees = {\"X_true\":X_trueEdge.iloc[:,:-1],\n",
        "                                        \"y_true\":y_true,\n",
        "                                        \"X_false\":X_falseEdge.iloc[:,:-1],\n",
        "                                        \"y_false\":y_false}\n",
        "\n",
        "        # we will construct new branch of tree if the variance_Reduction is larger than minimum variance_Reduction that we've defined\n",
        "        if largest_variance_Reduction > self.min_VarianceReduction:\n",
        "            true_branch = self.build_tree(subtrees[\"X_true\"], subtrees[\"y_true\"], current_depth+1)\n",
        "            false_branch = self.build_tree(subtrees[\"X_false\"], subtrees[\"y_false\"], current_depth+1)\n",
        "            return DecisionNode(feature_idx=decision[\"feature_idx\"], threshold=decision[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
        "\n",
        "        # at leaf node we calculate the mean for the records\n",
        "        leaf_value = self.majority_vote(y)\n",
        "        return DecisionNode(value=leaf_value)\n",
        "                        \n",
        "    # measure the impurity by using variance reduction measure (like MSE)\n",
        "    # left_edgeRec= True edge: where condition is true\n",
        "    # Right_edgeRec= False edge: where condition is false\n",
        "    def Calc_variance_reduction(self, parentRec, left_edgeRec, Right_edgeRec):   \n",
        "        # return the VarReduction = variance for parent - (Weight * var(leftEdge) + Weight * var(RightEdge)\n",
        "        var_parent = np.var(parentRec)\n",
        "        \n",
        "        weight_left = len(left_edgeRec) / len(parentRec)\n",
        "        weight_right = len(Right_edgeRec) / len(parentRec)\n",
        "        var_left = np.var(left_edgeRec)\n",
        "        var_right = np.var(Right_edgeRec)\n",
        "\n",
        "        VarReduction = var_parent - (weight_left * var_left + weight_right * var_right)\n",
        "        return VarReduction\n",
        "        \n",
        "    \n",
        "    def majority_vote(self, Y): \n",
        "        # return the majority_vote for the leaf nodes \n",
        "        return Y.mean()\n",
        "        \n",
        "             \n",
        "    def split_by_feature(self, db, feature_idx, threshold):\n",
        "        # split the data into left_edge & right_edge depends one specified feature and the threshold\n",
        "        left_edge = db[db.iloc [:, feature_idx] <= threshold]\n",
        "        right_edge = db[db.iloc [:, feature_idx] > threshold]\n",
        "        # return left & right edges\n",
        "        return left_edge, right_edge\n",
        "\n",
        "    \n",
        "    # Used to train the dataset after spliting the data into x: features, y: target\n",
        "    def fit(self, X, y):\n",
        "        self.root = self.build_tree(X, y)\n",
        "\n",
        "\n",
        "    def predict_value(self, xTest, tree=None):\n",
        "        # recursive method to find the leaf node that corresponds to prediction\n",
        "        if tree is None:\n",
        "            tree = self.root\n",
        "        \n",
        "        # If it's a leaf node, return the value\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "        \n",
        "        if xTest[tree.feature_idx] <= tree.threshold:\n",
        "            return self.predict_value(xTest, tree.true_branch)\n",
        "        else:\n",
        "            return self.predict_value(xTest, tree.false_branch) \n",
        "\n",
        "    # to predict the value we need to pass the all records for features and we save the prediction for each records into a list\n",
        "    def predict(self, XTest):\n",
        "        y_pred = []\n",
        "        for idx, row in XTest.iterrows():           \n",
        "            y_pred.append(self.predict_value(row.values))\n",
        "        return y_pred\n",
        "    \n",
        "def CalcAccuracy(Actual_Y, Predicted_y):\n",
        "    Actual_Y = np.array(Actual_Y)\n",
        "    Predicted_y = np.array(Predicted_y)\n",
        "    \n",
        "    # Calculate the squared differences\n",
        "    squared_diff = (Actual_Y - Predicted_y) ** 2\n",
        "    \n",
        "    # Calculate the mean of the squared differences\n",
        "    mean_squared_diff = np.mean(squared_diff)\n",
        "    \n",
        "    # Take the square root to get RMSE\n",
        "    rmse = np.sqrt(mean_squared_diff)\n",
        "    \n",
        "    return rmse\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('housing_price_train.csv')\n",
        "test_df = pd.read_csv('housing_price_test.csv')\n",
        "\n",
        "# ai to generate this\n",
        "def enhanced_preprocessor(df):\n",
        "    # Convert numerical-categorical features\n",
        "    df['MSSubClass'] = df['MSSubClass'].astype(str)\n",
        "    \n",
        "    # Ordinal feature mappings (category -> numerical value)\n",
        "    ordinal_map = {\n",
        "        'ExterQual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'ExterCond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'BsmtQual': {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'BsmtCond': {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'BsmtExposure': {'NA':0, 'No':1, 'Mn':2, 'Av':3, 'Gd':4},\n",
        "        'HeatingQC': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'KitchenQual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'FireplaceQu': {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'GarageQual': {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'GarageCond': {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'PoolQC': {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n",
        "        'LandSlope': {'Sev':1, 'Mod':2, 'Gtl':3},\n",
        "        'LotShape': {'IR3':1, 'IR2':2, 'IR1':3, 'Reg':4},\n",
        "        'PavedDrive': {'N':0, 'P':1, 'Y':2},\n",
        "        'Functional': {'Sal':1, 'Sev':2, 'Maj2':3, 'Maj1':4, \n",
        "                      'Mod':5, 'Min2':6, 'Min1':7, 'Typ':8}\n",
        "    }\n",
        "    \n",
        "    # Apply ordinal mappings\n",
        "    for feature, mapping in ordinal_map.items():\n",
        "        df[feature] = df[feature].map(mapping).fillna(0).astype(int)\n",
        "    \n",
        "    # Handle missing values\n",
        "    na_features = {\n",
        "        'Alley': 'NoAlley',\n",
        "        'MasVnrType': 'None',\n",
        "        'Fence': 'NoFence',\n",
        "        'MiscFeature': 'None',\n",
        "        'FireplaceQu': 0,\n",
        "        'GarageType': 'NoGarage'\n",
        "    }\n",
        "    for feature, na_value in na_features.items():\n",
        "        df[feature].fillna(na_value, inplace=True)\n",
        "    \n",
        "    # Numerical features\n",
        "    num_features = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
        "                   'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
        "                   'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
        "                   '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageCars',\n",
        "                   'GarageArea', 'WoodDeckSF', 'OpenPorchSF']\n",
        "    for col in num_features:\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "    \n",
        "    # One-hot encode remaining categoricals\n",
        "    cat_features = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LandContour',\n",
        "                   'Utilities', 'LotConfig', 'Neighborhood', 'Condition1',\n",
        "                   'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle',\n",
        "                   'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
        "                   'Foundation', 'Heating', 'CentralAir', 'Electrical',\n",
        "                   'GarageType', 'SaleType', 'SaleCondition']\n",
        "    \n",
        "    df = pd.get_dummies(df, columns=cat_features, dummy_na=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Preprocess data\n",
        "X_train = enhanced_preprocessor(train_df.drop(['Id', 'SalePrice'], axis=1))\n",
        "y_train = np.log1p(train_df['SalePrice'])  # Log-transform target\n",
        "\n",
        "test_ids = test_df['Id']\n",
        "X_test = enhanced_preprocessor(test_df.drop('Id', axis=1))\n",
        "\n",
        "# Align features\n",
        "common_cols = X_train.columns.intersection(X_test.columns)\n",
        "X_train = X_train[common_cols]\n",
        "X_test = X_test[common_cols]\n",
        "\n",
        "# Initialize and train model\n",
        "tree_model = RegressionDecisionTree(\n",
        "    min_VarianceReduction=0.05,\n",
        "    max_depth=12\n",
        ")\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "log_predictions = tree_model.predict(X_test)\n",
        "predictions = np.expm1(log_predictions)  # Reverse log-transform\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'SalePrice': predictions\n",
        "})\n",
        "submission.to_csv('optimized_submission.csv', index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvzaxcPAoJsk"
      },
      "source": [
        "## Part 3: Random Forest (20 points)\n",
        "#### Random forest class\n",
        "- the Class consist of the following functions:\n",
        "<ul>\n",
        "    <li>Constructor: consists of the subset data (Training & Testing) dataset after preprocessing and a list of deciceion tree objects </li>    \n",
        "    <li>Subsampling: Bagging we will take random sample with replacement for the Training dataset </li>\n",
        "    <li>build_model: first make subsample for the training dataset, then split the data into featurespart(X) and targetpart(Y), then take 10 samples of the feature part, finally build the decision tree (fit), this function take the number of DT that we want to build</li>\n",
        "    <li>predict: take the test dataset and make the prediction for the target field in all the tree in the random forest then take the mean for the prediction in each tree, finally add the mean of prediction to a list of predition </li>\n",
        "\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a00zi12Q-SJO"
      },
      "outputs": [],
      "source": [
        "class RF(object):\n",
        "    def __init__(self):\n",
        "        self.Traindata = None  # training data set (loaded into memory)\n",
        "        self.Testdata = None  # Test data set for prediction        \n",
        "        self.trees = []  # list of decision trees \n",
        "          \n",
        "\n",
        "     # This function generate a subsample with replacement\n",
        "    def __subsampling(self, train_set, sample_size_ratio):       \n",
        "        #sample_number = round(len(train_set) * sample_size_ratio)\n",
        "        #return  train_set.sample(n = sample_number, replace=True)\n",
        "        # TODO\n",
        "        pass\n",
        "        \n",
        "        \n",
        "    def build_model(self, train_set, sample_size_ratio, number_of_trees):\n",
        "        for i in range(number_of_trees):\n",
        "            TrainingSample = self.__subsampling(train_set, sample_size_ratio)\n",
        "            # TODO\n",
        "            # build a  tree\n",
        "            # Train the tree\n",
        "            # Add the tree to the Treeslist\n",
        "        pass\n",
        "            \n",
        "               \n",
        "    def predict(self, test_set):\n",
        "        # TODO\n",
        "        # Predict for each item in the list \n",
        "        # Calculate the mean \n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITGUmaXc-SJO"
      },
      "source": [
        "### Create Random Forest\n",
        "\n",
        "* Create 10 Decision Tree in the randomforest\n",
        "* Train the random forest with the dataset\n",
        "* Use the created random forest to predict the test dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjqaGyyl-qoY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWmfgEVp-SJO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVGAlCDkoRfo"
      },
      "source": [
        "##Part4: Comparison! (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tHF7qjiBl6A"
      },
      "source": [
        "Now that you have finished implementing your Random Forest, it's time for some experiments and analysis! \n",
        "\n",
        "* Use the Random Forest in the scikit-learn library and train it on the same dataset. \n",
        "\n",
        "* Compare the accuracy given by your Random Forest to the scikit-learn one. \n",
        "\n",
        "* Increase the number of trees in your Random Forest. Does it improve the accuracy? \n",
        "\n",
        "* Make a table for comparing your Random Forest accuracy with different number of trees with the scikit-learn one. What is your conclusion? "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
